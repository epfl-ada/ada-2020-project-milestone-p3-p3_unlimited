{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Gone Awry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from convokit import download\n",
    "from convokit.prompt_types import PromptTypeWrapper\n",
    "from convokit import PolitenessStrategies\n",
    "from convokit import Corpus, Speaker, Utterance\n",
    "from convokit import Classifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at E:\\EPFL\\Courses\\Ada\\Project P4\\conversations-gone-awry-corpus\\conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "# OPTION 1: DOWNLOAD CORPUS \n",
    "# UNCOMMENT THESE LINES TO DOWNLOAD CORPUS\n",
    "# DATA_DIR = ''\n",
    "#AWRY_ROOT_DIR = download('conversations-gone-awry-corpus', data_dir=DATA_DIR)\n",
    "\n",
    "# OPTION 2: READ PREVIOUSLY-DOWNLOADED CORPUS FROM DISK\n",
    "# UNCOMMENT THIS LINE AND REPLACE WITH THE DIRECTORY WHERE THE TENNIS-CORPUS IS LOCATED\n",
    "DATA_DIR = 'E:\\EPFL\\Courses\\Ada\\Project P4\\conversations-gone-awry-corpus'\n",
    "AWRY_ROOT_DIR = download('conversations-gone-awry-corpus', data_dir=DATA_DIR)\n",
    "\n",
    "awry_corpus = Corpus(AWRY_ROOT_DIR)\n",
    "awry_corpus.load_info('utterance',['parsed'])\n",
    "\n",
    "awry_corpus = awry_corpus.filter_conversations_by(lambda convo: convo.meta['annotation_year'] == '2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 2010\n",
      "Number of Utterances: 6363\n",
      "Number of Conversations: 1168\n"
     ]
    }
   ],
   "source": [
    "awry_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = awry_corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.is_section_header</th>\n",
       "      <th>meta.comment_has_personal_attack</th>\n",
       "      <th>meta.toxicity</th>\n",
       "      <th>meta.parsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320261990.20239.20239</th>\n",
       "      <td>1.25572e+09</td>\n",
       "      <td>Réginald, first of all, mea culpa. I hadn't n...</td>\n",
       "      <td>Rivertorch</td>\n",
       "      <td>320251126.19827.19814</td>\n",
       "      <td>320251126.19814.19814</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041406</td>\n",
       "      <td>[{'rt': 1, 'toks': [{'tok': ' ', 'tag': '', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202186098.20704.20684</th>\n",
       "      <td>1.20692e+09</td>\n",
       "      <td>and your text is klunky, sorry.</td>\n",
       "      <td>72.0.180.2</td>\n",
       "      <td>202186098.20684.20684</td>\n",
       "      <td>202186098.20684.20684</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.20241</td>\n",
       "      <td>[{'rt': 3, 'toks': [{'tok': 'and', 'tag': 'CC'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143878980.125.125</th>\n",
       "      <td>1.18412e+09</td>\n",
       "      <td>Friday did as much as he can, due to the curre...</td>\n",
       "      <td>Zscout370</td>\n",
       "      <td>143878851.103.103</td>\n",
       "      <td>143877368.8.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0239587</td>\n",
       "      <td>[{'rt': 1, 'toks': [{'tok': 'Friday', 'tag': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303464344.31333.31333</th>\n",
       "      <td>1.24823e+09</td>\n",
       "      <td>I see no reason how \"T.N.A\" is widely known ei...</td>\n",
       "      <td>Truco</td>\n",
       "      <td>303455587.31141.31141</td>\n",
       "      <td>303378306.30420.30420</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0169346</td>\n",
       "      <td>[{'rt': 1, 'toks': [{'tok': 'I', 'tag': 'PRP',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397617990.24140.24120</th>\n",
       "      <td>1.29014e+09</td>\n",
       "      <td>Hi, I noticed  is edit warring on the wiki_lin...</td>\n",
       "      <td>Aeonx</td>\n",
       "      <td>397617990.24120.24120</td>\n",
       "      <td>397617990.24120.24120</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388942</td>\n",
       "      <td>[{'rt': 3, 'toks': [{'tok': 'Hi', 'tag': 'UH',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62531862.7260.7260</th>\n",
       "      <td>1.15227e+09</td>\n",
       "      <td>The \"Old\" onscreen character of Shawn Michaels...</td>\n",
       "      <td>Da Main Event</td>\n",
       "      <td>46687240.5546.5546</td>\n",
       "      <td>46687240.5546.5546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.233057</td>\n",
       "      <td>[{'rt': 11, 'toks': [{'tok': 'The', 'tag': 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162520051.1295.1295</th>\n",
       "      <td>1.19161e+09</td>\n",
       "      <td>To re-iterate what ''Metros'' said, the sectio...</td>\n",
       "      <td>Kralizec!</td>\n",
       "      <td>162513218.1202.1202</td>\n",
       "      <td>159674239.677.485</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.110268</td>\n",
       "      <td>[{'rt': 16, 'toks': [{'tok': 'To', 'tag': 'TO'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193649667.12093.12093</th>\n",
       "      <td>1.20385e+09</td>\n",
       "      <td>\\n== Edit warring on [WIKI_LINK: 9/11 conspira...</td>\n",
       "      <td>Ice Cold Beer</td>\n",
       "      <td>None</td>\n",
       "      <td>193649667.12093.12093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'rt': 1, 'toks': [{'tok': '\\n', 'tag': '', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228520950.6187.6187</th>\n",
       "      <td>1.2173e+09</td>\n",
       "      <td>I can't work out whether you are an idiot or w...</td>\n",
       "      <td>Matilda</td>\n",
       "      <td>228468167.5015.5005</td>\n",
       "      <td>228468167.5005.5005</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.826419</td>\n",
       "      <td>[{'rt': 3, 'toks': [{'tok': 'I', 'tag': 'PRP',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80315439.464.464</th>\n",
       "      <td>1.16035e+09</td>\n",
       "      <td>I agree, great work. I, for some reason, wasn'...</td>\n",
       "      <td>LiquidGhoul</td>\n",
       "      <td>80287913.451.432</td>\n",
       "      <td>80287913.432.432</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00942597</td>\n",
       "      <td>[{'rt': 1, 'toks': [{'tok': 'I', 'tag': 'PRP',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp  \\\n",
       "id                                   \n",
       "320261990.20239.20239  1.25572e+09   \n",
       "202186098.20704.20684  1.20692e+09   \n",
       "143878980.125.125      1.18412e+09   \n",
       "303464344.31333.31333  1.24823e+09   \n",
       "397617990.24140.24120  1.29014e+09   \n",
       "62531862.7260.7260     1.15227e+09   \n",
       "162520051.1295.1295    1.19161e+09   \n",
       "193649667.12093.12093  1.20385e+09   \n",
       "228520950.6187.6187     1.2173e+09   \n",
       "80315439.464.464       1.16035e+09   \n",
       "\n",
       "                                                                    text  \\\n",
       "id                                                                         \n",
       "320261990.20239.20239   Réginald, first of all, mea culpa. I hadn't n...   \n",
       "202186098.20704.20684                   and your text is klunky, sorry.    \n",
       "143878980.125.125      Friday did as much as he can, due to the curre...   \n",
       "303464344.31333.31333  I see no reason how \"T.N.A\" is widely known ei...   \n",
       "397617990.24140.24120  Hi, I noticed  is edit warring on the wiki_lin...   \n",
       "62531862.7260.7260     The \"Old\" onscreen character of Shawn Michaels...   \n",
       "162520051.1295.1295    To re-iterate what ''Metros'' said, the sectio...   \n",
       "193649667.12093.12093  \\n== Edit warring on [WIKI_LINK: 9/11 conspira...   \n",
       "228520950.6187.6187    I can't work out whether you are an idiot or w...   \n",
       "80315439.464.464       I agree, great work. I, for some reason, wasn'...   \n",
       "\n",
       "                             speaker               reply_to  \\\n",
       "id                                                            \n",
       "320261990.20239.20239     Rivertorch  320251126.19827.19814   \n",
       "202186098.20704.20684     72.0.180.2  202186098.20684.20684   \n",
       "143878980.125.125          Zscout370      143878851.103.103   \n",
       "303464344.31333.31333          Truco  303455587.31141.31141   \n",
       "397617990.24140.24120          Aeonx  397617990.24120.24120   \n",
       "62531862.7260.7260     Da Main Event     46687240.5546.5546   \n",
       "162520051.1295.1295        Kralizec!    162513218.1202.1202   \n",
       "193649667.12093.12093  Ice Cold Beer                   None   \n",
       "228520950.6187.6187          Matilda    228468167.5015.5005   \n",
       "80315439.464.464         LiquidGhoul       80287913.451.432   \n",
       "\n",
       "                             conversation_id meta.is_section_header  \\\n",
       "id                                                                    \n",
       "320261990.20239.20239  320251126.19814.19814                  False   \n",
       "202186098.20704.20684  202186098.20684.20684                  False   \n",
       "143878980.125.125              143877368.8.8                  False   \n",
       "303464344.31333.31333  303378306.30420.30420                  False   \n",
       "397617990.24140.24120  397617990.24120.24120                  False   \n",
       "62531862.7260.7260        46687240.5546.5546                  False   \n",
       "162520051.1295.1295        159674239.677.485                  False   \n",
       "193649667.12093.12093  193649667.12093.12093                   True   \n",
       "228520950.6187.6187      228468167.5005.5005                  False   \n",
       "80315439.464.464            80287913.432.432                  False   \n",
       "\n",
       "                      meta.comment_has_personal_attack meta.toxicity  \\\n",
       "id                                                                     \n",
       "320261990.20239.20239                            False      0.041406   \n",
       "202186098.20704.20684                            False       0.20241   \n",
       "143878980.125.125                                False     0.0239587   \n",
       "303464344.31333.31333                            False     0.0169346   \n",
       "397617990.24140.24120                            False      0.388942   \n",
       "62531862.7260.7260                               False      0.233057   \n",
       "162520051.1295.1295                              False      0.110268   \n",
       "193649667.12093.12093                            False             0   \n",
       "228520950.6187.6187                               True      0.826419   \n",
       "80315439.464.464                                 False    0.00942597   \n",
       "\n",
       "                                                             meta.parsed  \n",
       "id                                                                        \n",
       "320261990.20239.20239  [{'rt': 1, 'toks': [{'tok': ' ', 'tag': '', 'd...  \n",
       "202186098.20704.20684  [{'rt': 3, 'toks': [{'tok': 'and', 'tag': 'CC'...  \n",
       "143878980.125.125      [{'rt': 1, 'toks': [{'tok': 'Friday', 'tag': '...  \n",
       "303464344.31333.31333  [{'rt': 1, 'toks': [{'tok': 'I', 'tag': 'PRP',...  \n",
       "397617990.24140.24120  [{'rt': 3, 'toks': [{'tok': 'Hi', 'tag': 'UH',...  \n",
       "62531862.7260.7260     [{'rt': 11, 'toks': [{'tok': 'The', 'tag': 'DT...  \n",
       "162520051.1295.1295    [{'rt': 16, 'toks': [{'tok': 'To', 'tag': 'TO'...  \n",
       "193649667.12093.12093  [{'rt': 1, 'toks': [{'tok': '\\n', 'tag': '', '...  \n",
       "228520950.6187.6187    [{'rt': 3, 'toks': [{'tok': 'I', 'tag': 'PRP',...  \n",
       "80315439.464.464       [{'rt': 1, 'toks': [{'tok': 'I', 'tag': 'PRP',...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncnt = 0\\nfor utt in awry_corpus.iter_utterances():\\n    cnt += 1\\n    print(ps.transform_utterance(utt))\\n    if cnt > 2:\\n        break\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cnt = 0\n",
    "for utt in awry_corpus.iter_utterances():\n",
    "    cnt += 1\n",
    "    print(ps.transform_utterance(utt))\n",
    "    if cnt > 2:\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Politeness: Use wiki_corpus for training, then apply the classifier on awry_corpus to get the prediction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\Siran\\.convokit\\downloads\\wikipedia-politeness-corpus\n"
     ]
    }
   ],
   "source": [
    "# Downloading the wikipedia portion of annotated data\n",
    "wiki_corpus = Corpus(download(\"wikipedia-politeness-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 1\n",
      "Number of Utterances: 4353\n",
      "Number of Conversations: 4353\n"
     ]
    }
   ],
   "source": [
    "wiki_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies()\n",
    "awry_corpus = ps.transform(awry_corpus, markers=True)\n",
    "wiki_corpus = ps.transform(wiki_corpus, markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = awry_corpus.get_utterance_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 4353, test size = 6363\n"
     ]
    }
   ],
   "source": [
    "train_corpus = Corpus(utterances=[utt for utt in wiki_corpus.iter_utterances()])\n",
    "test_corpus = Corpus(utterances=[utt for utt in awry_corpus.iter_utterances()])\n",
    "print(\"train size = {}, test size = {}\".format(len(train_corpus.get_utterance_ids()),\n",
    "                                               len(test_corpus.get_utterance_ids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default classification model (standard scaled logistic regression).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.classifier.classifier.Classifier at 0x26414761a60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Classifier(obj_type=\"utterance\", \n",
    "                        pred_feats=[\"politeness_strategies\"], \n",
    "                        labeller=lambda utt: utt.meta['Binary'] == 1)\n",
    "clf.fit(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132662410.11977.11977</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410838569.61940.61940</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236161634.27143.27131</th>\n",
       "      <td>0</td>\n",
       "      <td>0.020131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444898053.3389.3389</th>\n",
       "      <td>0</td>\n",
       "      <td>0.020926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418695946.3459.3449</th>\n",
       "      <td>0</td>\n",
       "      <td>0.020926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36146600.3862.3862</th>\n",
       "      <td>0</td>\n",
       "      <td>0.021219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606915191.4713.4713</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408191172.17962.17962</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344941369.12789.12789</th>\n",
       "      <td>0</td>\n",
       "      <td>0.023541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123265296.5701.5701</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349271207.4653.4653</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219409911.27840.27840</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311233422.1261.1251</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91238339.9018.9018</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48223090.8116.8092</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335849428.5696.5696</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473839577.3080.3080</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36603478.9519.9519</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286807.842.842</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744949047.2954.2940</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prediction  pred_score\n",
       "id                                           \n",
       "132662410.11977.11977           0    0.009742\n",
       "410838569.61940.61940           0    0.019028\n",
       "236161634.27143.27131           0    0.020131\n",
       "444898053.3389.3389             0    0.020926\n",
       "418695946.3459.3449             0    0.020926\n",
       "36146600.3862.3862              0    0.021219\n",
       "606915191.4713.4713             0    0.022217\n",
       "408191172.17962.17962           0    0.022496\n",
       "344941369.12789.12789           0    0.023541\n",
       "123265296.5701.5701             0    0.024656\n",
       "349271207.4653.4653             0    0.026663\n",
       "219409911.27840.27840           0    0.027075\n",
       "311233422.1261.1251             0    0.027358\n",
       "91238339.9018.9018              0    0.027662\n",
       "48223090.8116.8092              0    0.027662\n",
       "335849428.5696.5696             0    0.027662\n",
       "473839577.3080.3080             0    0.029251\n",
       "36603478.9519.9519              0    0.029723\n",
       "14286807.842.842                0    0.029723\n",
       "744949047.2954.2940             0    0.029893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = clf.summarize(test_pred)\n",
    "pred_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I dont want to seem rude or anything, but is there a reason external_link has gone unanswered and several have been resolved below? This editor and his suspected sockpuppets are continuing to commit rogue edits and action needs to be taken. Its getting frustrating to work on the page in question. Thanks,'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances.loc['473786014.2964.2956'].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584\n"
     ]
    }
   ],
   "source": [
    "utt_with_attack = utterances[utterances['meta.comment_has_personal_attack']==True]\n",
    "utt_attack_ids = utt_with_attack.index\n",
    "print(len(utt_attack_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.is_section_header</th>\n",
       "      <th>meta.comment_has_personal_attack</th>\n",
       "      <th>meta.toxicity</th>\n",
       "      <th>meta.parsed</th>\n",
       "      <th>meta.politeness_strategies</th>\n",
       "      <th>meta.politeness_markers</th>\n",
       "      <th>meta.prediction</th>\n",
       "      <th>meta.pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291906834.15472.15472</th>\n",
       "      <td>1.24314e+09</td>\n",
       "      <td>==Vandalism==\\n</td>\n",
       "      <td>Sherzo</td>\n",
       "      <td>None</td>\n",
       "      <td>291906834.15472.15472</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'rt': 2, 'toks': [{'tok': '=', 'tag': 'SYM',...</td>\n",
       "      <td>{'feature_politeness_==Please==': 0, 'feature_...</td>\n",
       "      <td>{'politeness_markers_==Please==': [], 'politen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0833594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324569832.859.859</th>\n",
       "      <td>1.25766e+09</td>\n",
       "      <td>== [WIKI_LINK: List of Morphoses productions|M...</td>\n",
       "      <td>Robertgreer</td>\n",
       "      <td>None</td>\n",
       "      <td>324569832.859.859</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'rt': 3, 'toks': [{'tok': '=', 'tag': 'NFP',...</td>\n",
       "      <td>{'feature_politeness_==Please==': 0, 'feature_...</td>\n",
       "      <td>{'politeness_markers_==Please==': [], 'politen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0833594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75698786.4387.4387</th>\n",
       "      <td>1.15824e+09</td>\n",
       "      <td>I was surprised that so many people were willi...</td>\n",
       "      <td>Steel</td>\n",
       "      <td>75697745.4315.4315</td>\n",
       "      <td>75692435.4172.4172</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.128427</td>\n",
       "      <td>[{'rt': 1, 'toks': [{'tok': 'i', 'tag': 'PRP',...</td>\n",
       "      <td>{'feature_politeness_==Please==': 0, 'feature_...</td>\n",
       "      <td>{'politeness_markers_==Please==': [], 'politen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0948002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp  \\\n",
       "id                                   \n",
       "291906834.15472.15472  1.24314e+09   \n",
       "324569832.859.859      1.25766e+09   \n",
       "75698786.4387.4387     1.15824e+09   \n",
       "\n",
       "                                                                    text  \\\n",
       "id                                                                         \n",
       "291906834.15472.15472                                    ==Vandalism==\\n   \n",
       "324569832.859.859      == [WIKI_LINK: List of Morphoses productions|M...   \n",
       "75698786.4387.4387     I was surprised that so many people were willi...   \n",
       "\n",
       "                           speaker            reply_to        conversation_id  \\\n",
       "id                                                                              \n",
       "291906834.15472.15472       Sherzo                None  291906834.15472.15472   \n",
       "324569832.859.859      Robertgreer                None      324569832.859.859   \n",
       "75698786.4387.4387           Steel  75697745.4315.4315     75692435.4172.4172   \n",
       "\n",
       "                      meta.is_section_header meta.comment_has_personal_attack  \\\n",
       "id                                                                              \n",
       "291906834.15472.15472                   True                            False   \n",
       "324569832.859.859                       True                            False   \n",
       "75698786.4387.4387                     False                            False   \n",
       "\n",
       "                      meta.toxicity  \\\n",
       "id                                    \n",
       "291906834.15472.15472             0   \n",
       "324569832.859.859                 0   \n",
       "75698786.4387.4387         0.128427   \n",
       "\n",
       "                                                             meta.parsed  \\\n",
       "id                                                                         \n",
       "291906834.15472.15472  [{'rt': 2, 'toks': [{'tok': '=', 'tag': 'SYM',...   \n",
       "324569832.859.859      [{'rt': 3, 'toks': [{'tok': '=', 'tag': 'NFP',...   \n",
       "75698786.4387.4387     [{'rt': 1, 'toks': [{'tok': 'i', 'tag': 'PRP',...   \n",
       "\n",
       "                                              meta.politeness_strategies  \\\n",
       "id                                                                         \n",
       "291906834.15472.15472  {'feature_politeness_==Please==': 0, 'feature_...   \n",
       "324569832.859.859      {'feature_politeness_==Please==': 0, 'feature_...   \n",
       "75698786.4387.4387     {'feature_politeness_==Please==': 0, 'feature_...   \n",
       "\n",
       "                                                 meta.politeness_markers  \\\n",
       "id                                                                         \n",
       "291906834.15472.15472  {'politeness_markers_==Please==': [], 'politen...   \n",
       "324569832.859.859      {'politeness_markers_==Please==': [], 'politen...   \n",
       "75698786.4387.4387     {'politeness_markers_==Please==': [], 'politen...   \n",
       "\n",
       "                      meta.prediction meta.pred_score  \n",
       "id                                                     \n",
       "291906834.15472.15472               0       0.0833594  \n",
       "324569832.859.859                   0       0.0833594  \n",
       "75698786.4387.4387                  0       0.0948002  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_utters_df = test_corpus.get_utterances_dataframe()\n",
    "test_utters_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18280225979968742\n"
     ]
    }
   ],
   "source": [
    "avg_polite_ness = 0\n",
    "for u_id in utt_attack_ids:\n",
    "    pred_score = test_utters_df.loc[u_id]['meta.pred_score']\n",
    "    avg_polite_ness += pred_score\n",
    "\n",
    "print(avg_polite_ness / len(utt_attack_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5779\n"
     ]
    }
   ],
   "source": [
    "utt_without_attack = utterances[utterances['meta.comment_has_personal_attack']==False]\n",
    "utt_non_attack_ids = utt_without_attack.index\n",
    "print(len(utt_non_attack_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.222397808980296\n"
     ]
    }
   ],
   "source": [
    "avg_polite_ness = 0\n",
    "for u_id in utt_non_attack_ids:\n",
    "    pred_score = test_utters_df.loc[u_id]['meta.pred_score']\n",
    "    avg_polite_ness += pred_score\n",
    "\n",
    "print(avg_polite_ness / len(utt_non_attack_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755\n"
     ]
    }
   ],
   "source": [
    "pred_1 = pred_df[pred_df['prediction']==1]\n",
    "utt_pos_ids = pred_1.index\n",
    "print(len(utt_pos_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5194615104243733\n",
      "What a pathetic joke. False claims of harassment. You pinged me somewhere in the vicinity of six times after I asked you to stop. My first request reads- 'Don't ping me every time. '''This page is on my watch list.''' Thank you.' So besides turning down a polite request, you '''now lie''' to another User. As I said, a pathetic joke., is the complaint department really on \n",
      "0.5528330006161977\n",
      "Lord, I apologize!!!! Even though I'm an atheist and I have a Buddhist girlfriend... Uncle Tech OK, what I was doing was NOT vandalism! Unblock me!! I have a history of good edits. Unblock me!!!! Unblock me, or at least hear me out Seriously, this site isn't the same without me... unblock me!!!!!!!!!!!! Is anybody listening or caring? unblock me unblock me seriously... UNBLOCK ME!!!!!!!!!!!!!! wow...... unblock me unblock me unblock me FUCKING UNBLOCK ME!!!!!!!!! \n",
      "0.5565269776610304\n",
      "Sorry, I have some decorating to do, so I can't start on the picture right now. If you believe I have any connection to 62.136.238.65 you'd better dob me in. Don't worry, I've got a fairly thick skin and I think you are a lying cunt  o) \n",
      "0.5603511527448884\n",
      "But you reserve the right to not have a place where people can talk to you about your editing habits? Or ask you a question about about your edits? Sorry, not interested in maintaining that kind of communicative power imbalance. I asked you not to post on my talk page again. Don't do it. Posting on an editor's talk page after they have asked you not to is harassment and a blockable offense, you little hypocrite. \n",
      "0.5644127590781591\n",
      "Sorry dud, but '''''you''''' created the red link!  Somehow, you fixed it before I got to it.  My point that your're a jerk still stands, so beat it!@&*&$% \n",
      "0.5699253260356401\n",
      " Go ahead and threaten me - I welcome it.  Your version is pure trash, and so I am very happy to let it stand as is now.  It is a testament to your inability to write coherent articles.  All you do is revert edits and do not provide anything constructive to the Wikipedia community, as your contrib pages show.  Good luck. - Cindy\n",
      "0.5916306855751081\n",
      " Fuck you. Your deletion was incivil. Go ahead, ban me! Assholes like you are fucking it up for the ordinary users around here. Its even in the news now: the external_link. We don't need people like you around any more  if you make a mistake, admit it. Say your sorry. But don't fucking sit here an threaten me with banning if your goddamn ego is so frail-thin that you can't even bother to say \"Gee, I'm sorry, I made a mistake\" when you make a mistake.\n",
      ":::Between the assorted asshole admins that Jimbo Wales thinks are peachy-keen, and the incessent vandals, I've pretty much had it with WP. I say its time for new leadership around here.\n",
      "0.6291494448519961\n",
      "Well, you obviously don't comprehend the underlying issue. I am sorry for your parents for giving birth to a retarded child. \n",
      "0.6493841723242979\n",
      "Thanks for the solid advice wiki_link. \"Being right about an issue does not mean you're not being a dick! Dicks can be right — but they're still dicks; if there's something in what they say that is worth hearing, it goes unheard, because no one likes listening to dicks. It doesn't matter how right they are.\"wiki_link \n",
      "0.6531324160472636\n",
      "Absolute rubbish, if you want to opine go do it somewhere else. Thanks, \n",
      "0.6531324160472636\n",
      " You're useless.  Thanks.  )\n",
      "0.6575764472515159\n",
      " Um Ludvikus: Can't you read your own words? You wrote the word \"SHIT\" at least twice at wiki_link: \"There only are all the many different imprints of the same SHIT which too many people believe\" and \"I'm only interested in identifying the exact imprints of this antisemitic SHIT\" and as far as I know the word wiki_link is an obscenity. Then you used this language when talkng to another user at wiki_link: \"Fork? Fork you Mikka (just kidding). You're misrepresenting my position...\" and as you seem to think it's funny to say \"fork you\" clearly intending \"wiki_link you\" (since you have to add the disclaimer \"just kidding\") since these are clear obscenities. No doubt there are many more cases like this 'cause I have just had the great pleasure of meeting you now as an editor. And let me tell you, you cannot fool me with either your claim to innocence (when you deny your own opne obscenities) nor with your self-righteousness. Thanks,\n",
      "0.6599144844234108\n",
      "First you troll, then you threaten.  Good tactic.  Howsabout you just report me to all of your admin friends and have me banned?  Because you're not going to do it.  I dare you. I double-dog dare you.  Did a little checking on your history and, well, you've got a history of harassing, taunting, threatening, and baiting. \n",
      "0.6661846790913983\n",
      "wiki_link  Good luck with your DYK...  |    | \n",
      "0.6668638219474851\n",
      "How completely inappropriate of me to address you as \"Miss Aphrodesiac\". I am so sorry. How can I make it up to you. ::::\"My username kind of invites that sort of joke\"??? Are you retarded? If you are not, please email me so I can stop looking at your blatant sense of humor spewed out for all to see being contradicted by your latest attempt at politically correct '''(PUKE)''' flirtation with Paul. \n",
      "0.6783153216096964\n",
      " Excuse me, but you are completely wrong about every single point up above.  I'm extremely busy at the moment, but if you don't start to correct your false assumptions up above by doing some basic research, I'm going to haul your ignorant, lazy ass to the noticeboards, where you will be immediately schooled in your arrogant stupidity.  Now you either get off your lazy ass and figure out why and how you are wrong or you take these articles off of your watchlist and better hope I never run into you again.  I've seen some stupidity in my time but yours sir, takes the cake.\n",
      "0.6870362980856478\n",
      " Try external_link then.  The quote (as I'm sure you'll not be fucked to actually go and look at it for yourself) is\n",
      "\"Howard Street and Sheaf Square\n",
      "::::Sheaf Square will be redesigned as the principal gateway to the city centre and Howard Street as the pedestrian spine linking the station to the city centre.\"\n",
      "::::Well looky here, Sheaf Square is the gateway  Now, weren't you just saying that?  Oh not wait, I was.  Please, I beg of you, apply the following 3-step plan:\n",
      "locate hand\n",
      "insert hand up own arse\n",
      "remove head from said arse\n",
      "::::Thank you.  |\n",
      "0.6942399092767161\n",
      "Are you a robot? Never mind, you're just acting a real wiki_link here, to keep it in a Wikipedian kind of language. Life happily ever after, ruining other people's aspirations and ambitions here on Wikipedia. Way to go dude. Sorry for my offensiveness by the way, but you weren't quite as polite to me either. I'm just kind of mad at you. \n",
      "0.6946137499136462\n",
      " Alison, please accept my sincere apologies for not being able to properly or fully document the citation.\n",
      "Also please accept my sincere apologies for not being able to finish the edit that I had in progress at the time of this 3RR block.\n",
      "Citing someone out of context is NOT something I do. And citing someone without telling them, is also NOT something I do.\n",
      "I consider it rude and improper. All I can say is that i was in the middle of an edit on your page, when the 3RR block stopped me from letting you know. I had not yet gone back to wikipediatrix's page to cite the source of the quote on your userpage and that specific area. I am terribly sorry.\n",
      "You are correct, I need to step away. Smee is being a very large dick and is laughing about it. He won. Smee stop being a dickhead(whatever the citation for that page is). You cant even honor your promise to stay away from my page for 5 minutes without breaking your word.\n",
      "0.6954907263012791\n",
      " I see. Does it make you feel powerful to be a wiki_link? I'm sorry you're such an unhappy person. \n",
      "0.6954907263012791\n",
      "****I'm sorry if you don't understand my first sentence. I, on the other hand, don't know what you mean with 'vacuum.' I also don't see why the two of you seem to do everything you can to scare off this new editor. I've already cited what SamEV had to say (a rather unfriendly message), so that's not news. The problem is not the IP editor, the problem is that they don't know the rules because no one (that means you and SamEV) bothered to explain those to them. I suggest you read wiki_link carefully, and summarize that behavioral guideline for SamEV on their talk page. ****Oh, and undoing their edits one more time, that is not just asinine, it's also a pretty blatant violation of another rule, which I have already warned you aboutI'll do so now with a template on your talk page. I don't need your response here: if you wish to do anything to improve this, apologize to that IP editor for acting like a jackass and try to explain ''in friendly words'' what you think the problem is. \n",
      "0.697158699346315\n",
      "And I would greatly appreciate it if you could keep your hypocritical niceties off my page. \n",
      "0.7006316605133719\n",
      " When did I say I owned the article. Is not the computer's font legible for you?! Thanks for the gibberish. Pathetic Excuse by the way.\n",
      "0.7234013574130151\n",
      "If it was in fact \"consensus\" it would be in writing on the notability page. Your problem seems not with me but the guidelines, in the future leave me out of it and don't waste my time. You should bring it up wiki_link if you want some thing done. Good day. :::It's obviously not. If it's consensus then why would it not be on the wiki_link page. I'm not going to listen to what you think notability is, but if the guidelines change I will follow them. ::::I have asked three separate editors and they can't find anything that says \"minor leaguers are not notable enough for their own article,\" like you said. I'm going to believe wiki_link over you unless you prove there is a \"consensus.\" ::::: and  at the same time (he deleted the discussion so here is the external_link) and   who couldn't produce the \"consensus\" you spoke of. You say \"it was agreed to at wiki_link a while ago\" but wiki_link is WP:Baseball and it says ''\"Minor league players, managers, coaches, executives, and umpires are not assumed to be inherently notable. '''To establish that one of these is notable, the article must cite published secondary source material which is reliable, intellectually independent, and independent of the subject.\"''''' You're making up a consensus and I'm not buying it. ::::::You could have done that without wasting my time! And when you say \"A while ago the user:Gjr rodriguez created a bunch of minor league players\" gives me no point of reference. The wiki_link page was updated in April of this year. If there was \"consensus\" it would have been changed. :::::::Haha, coming from the user that said \"So dont be a fucking wise ass\" to me and also made edit summaries like external_link, external_link, external_link and countless others. Who's the pot calling the kettle black? ::::::::Yeah, maybe you're right. I'm sorry if I offended you. I just felt, I wasn't going to change you mind and you weren't going to change mine. Also, a point of interest for you may be wiki_link. Good luck with your discussion on wiki_link. \n",
      "0.7235075577174997\n",
      " I am not an American and I am not a fan of this silly programme, just trying to clean up after you. You didn't bother to learn about our policies before turning this stupid article into a tumour and then even making it spread. But I am supposed to learn the details of American copyright law before I am allowed to help you? Thank you very much.\n",
      "0.7251692928405525\n",
      "You know, it's really stupid when you believe that I changed that because I think I'm right or something. I haven't edited that page in God knows how long. I'd really appreciate it if you would stop being so damn rude - it's making me think you're really immature. () \n",
      "0.7296596230884351\n",
      "Hey screw you IP! ) (oops) \n",
      "0.7609102434582236\n",
      "Good luck with your collection:-) I would not be surprised, if an \"useful idiot\" will file that AE for you. Please have a nice day. \n",
      "0.7712755269992213\n",
      "Aha, that's where I've seen you. I think I saw Wirtland on ANI or somewhere like that. It is good that Witizen is willing to come along- it's hard with COI editors sometimes. Nice to know you are fellow moto scum! \n",
      "0.774111471842765\n",
      "I'm not going to continue this discussion.  If you fail to see your error (all population estimates have to be from the same ''official'' source), then that's your problem.  Take your snarky ass elsewhere.  Thanks. \n",
      "0.7920385442456986\n",
      "thank you for being an dick and not politley correct me, i made an honest mistake i was just trying to help. ( ) \n",
      "0.8120454350604491\n",
      "I don't fucking believe it. I can't believe you've already cleared that out. Essjay, you kick serious, serious ass. You get the beating-the-shit-out-of-everybody award. I'd give you a barnstar, but your insanely mad skills trump everything that those wimpy pentagrams have to offer. Thanks a million, you external_link. HOOAH! \n",
      "0.8389895463229091\n",
      "Obviously! There's no other possible conclusion. Please read up on things before throwing around such accusations, thanks. If you'd bothered to check your facts, I've routinely favored finding workable solutions to this problem for quite some time, now. If you want my help, don't be an asshole about it. – \n",
      "0.8509713278004979\n",
      " No, that is a suggestion, not an official policy that all users have to follow. Nobody contested it, and I'm not quite sure why you're bitching now. So please, leave it alone and don't harass me over it. Thank you.\n",
      "0.8587211953271603\n",
      " LOL inhumer. don't need to be like that you fag. I was suggesting, at that is what a wiki is for, if you really think aswell that I give a shit, please contact the plebianshitcom. Thanks mate, now im anrgy, I am going to kill a cow.\n",
      "0.9047877845121549\n",
      "Yeah, cause you come off real...\"impartial.\" Well, keep your accusational musings off my talk page, please. If you feel the need to strike up a conversation, feel free, but don't come around saying stupid shit. Thank you. \n",
      "0.9573318143361743\n",
      " Do you always have to be such a condescending dick? I was merely asking a simple question. I apologize for getting his name wrong (one letter off, and you have to correct me?). And, I checked the IMDb, and didn't find it on there; that is why I was confused. Except for that Xbox live thing, I couldn't find anything about it. So, thank you for the information, but try and keep the condescension to a minimum. \"Hope this helps\", asshole.\n",
      "0.9613320346765474\n",
      "Nice.  Well said.  His most recent external_link on my talk page says that this is a matter of principle!  I fail to see how this can be reconciled with his behaviour, i.e., calling me a \"faggot,\" etc.  *yawn*  This kind of shit really gets old, y'know?  Thanks for your response. -'''' \n",
      "0.9641942421623768\n",
      " This is both weird and boring to have this discussion now.  Orlady has cumulatively complained about there being articles on NRHP-listed places a few hundred times to me before.  Here it is misleading for Orlady to assert with sources that \"guided tours of the 'Jonesborough Historic District' are one of the main tourist attractions\" when none of the sources give that name.  I do see one more mention of \"Jonesborough's Historic District\" in one of those, but in fact not a single proper noun naming for the district.  In fact, calling it \"Jonesboro Historic District\" as it was and apparently still is named, provides a nice historical touch reflecting the fact that the town was for much of its history named Jonesboro.  Orlady has argued against use of wiki_links or other coinings of terms elsewhere;  here i think it would be wrong also to coin an artifical term when the quaint historic one is available and documented and accurate. Thanks for those links;  i'll take a look at them.  No thanks for your vote of no confidence that the NRHP document will provide no information on the metes and bounds of the district, on any local arguments for it being listed, and so on.  Good thing i am not looking for your approval, Orlady, in my choosing to work on wikipedia articles in the state of Tennessee.  It seems pretty unwelcoming and unpleasant, that i should ask a question here on some factual matters and get back more of your sarcasm and derision.  I'm pretty used to it, but i would think it would be somewhat a negative for other editors to read this shit here.\n",
      "0.9721990811922341\n",
      " Maybe you should be removed because I know who you are. You already vandalized this article with your ED name and now you dare to come back with another name? Go back to your shitty encyclopedia crapatica or I will show all the Wikipedians here some outing informations about who you really are. I also consider to make an interesting outing article about you and your friend Campus on the FAQ page. It depends on you. ::Nice try Arguecat3... sorry.. Yariau Neko. By the way, you know I don't speak Japanese but I have asked my friend Forryga what Yariau neko means in Japanese. However, I will think about your \"cease fire agreement\" you made me on another place. Oh... before I forget, you should not use the asterisk here...it's typical for your shitty ED but this is Wikipedia. Use the colon next time. And now go away. Thanks. \n",
      "0.979158989898953\n",
      " Close the block please then. If you have access please delete my account too because I see no reason to be back if this is how admins favour certain POV. If you need a reason for that, ''sorry'' but here - \"Fuck you\". Thanks \n",
      "41 utterence has personal attack but was predicted to be polite.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for u_id in utt_pos_ids:\n",
    "    if test_utters_df.loc[u_id]['meta.comment_has_personal_attack'] == True:\n",
    "        cnt += 1\n",
    "        print(test_utters_df.loc[u_id]['meta.pred_score'])\n",
    "        print(test_utters_df.loc[u_id].text)\n",
    "print(\"{} utterence has personal attack but was predicted to be polite.\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nutterance_ids = awry_corpus.get_utterance_ids()\\nrows = []\\n\\ncnt = 0\\nfor uid in utterance_ids:\\n    cnt += 1\\n    print(awry_corpus.get_utterance(uid).meta)\\n    if cnt > 2:\\n        break\\n    #rows.append(awry_corpus.get_utterance(uid).meta[\"Normalized Score\"])\\n#politeness_strategies = pd.DataFrame(rows, index=utterance_ids)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "utterance_ids = awry_corpus.get_utterance_ids()\n",
    "rows = []\n",
    "\n",
    "cnt = 0\n",
    "for uid in utterance_ids:\n",
    "    cnt += 1\n",
    "    print(awry_corpus.get_utterance(uid).meta)\n",
    "    if cnt > 2:\n",
    "        break\n",
    "    #rows.append(awry_corpus.get_utterance(uid).meta[\"Normalized Score\"])\n",
    "#politeness_strategies = pd.DataFrame(rows, index=utterance_ids)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Read the citations to the SurveyUSA polls.  They give the exact language, which only specifies those five candidates.  If Ron Paul\\'s name was mentioned, he might poll more than they are showing, because people are more inclined to choose one of the available options.\\n::::*How does a \"minor\" candidate become a first-tier candidate if some of the polls don\\'t even specify him as an option?  We aren\\'t talking about 1-2% any more.  Paul has clearly risen above the \"margin of error\" argument at this point.  We should question the results of polls that do not even list him as an option, or allow him to be voted for (as the recording I\\'ve linked to shows).  At the very least, we should put an asterisk beside polls which do not allow all primary candidates to be voted for.  \"Other\" is clearly unreasonable as an option. -'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances.loc['176824876.14917.14917'].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in sentiments for each utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numSentence</th>\n",
       "      <th>numWords</th>\n",
       "      <th>totSentiment</th>\n",
       "      <th>avgSentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       numSentence  numWords  totSentiment  avgSentiment\n",
       "u_id                                                                    \n",
       "146743638.12652.12652            1         4           2.0      2.000000\n",
       "146743638.12667.12652            3        70           4.0      1.333333\n",
       "146842219.12874.12874            4        86           8.0      2.000000\n",
       "143890867.11926.11926            1         7           2.0      2.000000\n",
       "143890867.11944.11926            4        19           6.0      1.500000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = pd.read_csv('awry_sentiment.csv', index_col='u_id')\n",
    "sents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conv in awry_corpus.iter_conversations():\n",
    "    spk_list = conv.get_chronological_speaker_list()\n",
    "    spks = []\n",
    "    for item in spk_list:\n",
    "        spk = item.id\n",
    "        spks.append(spk)\n",
    "#    print(set(spks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_polite_1</th>\n",
       "      <th>pre_polite_2</th>\n",
       "      <th>attack_p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_con</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295689</td>\n",
       "      <td>0.737203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.234452</td>\n",
       "      <td>0.106919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.962891</td>\n",
       "      <td>0.083359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917265</td>\n",
       "      <td>0.189851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126228</td>\n",
       "      <td>0.132515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0.125389</td>\n",
       "      <td>0.148742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>0.350113</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>0.083359</td>\n",
       "      <td>0.067104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>0.278233</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>0.083359</td>\n",
       "      <td>0.059012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pre_polite_1  pre_polite_2  attack_p\n",
       "Num_con                                      \n",
       "0            0.295689      0.737203         1\n",
       "1            0.234452      0.106919         0\n",
       "2            0.962891      0.083359         1\n",
       "3            0.917265      0.189851         0\n",
       "4            0.126228      0.132515         1\n",
       "...               ...           ...       ...\n",
       "1163         0.125389      0.148742         1\n",
       "1164         0.350113      0.188946         1\n",
       "1165         0.083359      0.067104         0\n",
       "1166         0.278233      0.081918         1\n",
       "1167         0.083359      0.059012         0\n",
       "\n",
       "[1168 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pol = pd.read_csv('pred_politeness.csv')\n",
    "data_pol.columns=['pre_polite_1','pre_polite_2','attack_p']\n",
    "data_pol['attack_p']=data_pol['attack_p'].astype(int)\n",
    "data_pol = data_pol.rename_axis(\"Num_con\")\n",
    "data_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_sen_1</th>\n",
       "      <th>score_sen_2</th>\n",
       "      <th>attack_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_con</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score_sen_1  score_sen_2  attack_s\n",
       "Num_con                                    \n",
       "0           0.125000     0.166667         1\n",
       "1           1.000000     0.500000         0\n",
       "2           0.083333     1.000000         1\n",
       "3           0.200000     0.200000         0\n",
       "4           1.000000     0.125000         1\n",
       "...              ...          ...       ...\n",
       "1163        0.200000     0.055556         1\n",
       "1164        0.250000     0.166667         1\n",
       "1165        1.000000     0.333333         0\n",
       "1166        0.200000     0.250000         1\n",
       "1167        1.000000     0.500000         0\n",
       "\n",
       "[1168 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sen = pd.read_csv('pred_sentiment.csv')\n",
    "data_sen.columns=['score_sen_1','score_sen_2','attack_s']\n",
    "data_sen['attack_s']=data_sen['attack_s'].astype(int)\n",
    "data_sen = data_sen.rename_axis(\"Num_con\")\n",
    "data_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numword_1</th>\n",
       "      <th>numword_2</th>\n",
       "      <th>attack_t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_con</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>110.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>91.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>69.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         numword_1  numword_2  attack_t\n",
       "Num_con                                \n",
       "0            122.0      137.0         1\n",
       "1             17.0       36.0         0\n",
       "2            122.0        4.0         1\n",
       "3             44.0      129.0         0\n",
       "4              4.0      163.0         1\n",
       "...            ...        ...       ...\n",
       "1163         110.0      169.0         1\n",
       "1164          91.0      144.0         1\n",
       "1165           6.0       37.0         0\n",
       "1166          69.0       48.0         1\n",
       "1167           3.0       16.0         0\n",
       "\n",
       "[1168 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tal = pd.read_csv('pred_talkativeness.csv')\n",
    "data_tal.columns=['numword_1','numword_2','attack_t']\n",
    "data_tal['attack_t']=data_tal['attack_t'].astype(int)\n",
    "data_tal = data_tal.rename_axis(\"Num_con\")\n",
    "data_tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_polite_1</th>\n",
       "      <th>pre_polite_2</th>\n",
       "      <th>score_sen_1</th>\n",
       "      <th>score_sen_2</th>\n",
       "      <th>numword_1</th>\n",
       "      <th>numword_2</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_con</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295689</td>\n",
       "      <td>0.737203</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>122.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.234452</td>\n",
       "      <td>0.106919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.962891</td>\n",
       "      <td>0.083359</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917265</td>\n",
       "      <td>0.189851</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126228</td>\n",
       "      <td>0.132515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0.125389</td>\n",
       "      <td>0.148742</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>110.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>0.350113</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>0.083359</td>\n",
       "      <td>0.067104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>0.278233</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>0.083359</td>\n",
       "      <td>0.059012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pre_polite_1  pre_polite_2  score_sen_1  score_sen_2  numword_1  \\\n",
       "Num_con                                                                    \n",
       "0            0.295689      0.737203     0.125000     0.166667      122.0   \n",
       "1            0.234452      0.106919     1.000000     0.500000       17.0   \n",
       "2            0.962891      0.083359     0.083333     1.000000      122.0   \n",
       "3            0.917265      0.189851     0.200000     0.200000       44.0   \n",
       "4            0.126228      0.132515     1.000000     0.125000        4.0   \n",
       "...               ...           ...          ...          ...        ...   \n",
       "1163         0.125389      0.148742     0.200000     0.055556      110.0   \n",
       "1164         0.350113      0.188946     0.250000     0.166667       91.0   \n",
       "1165         0.083359      0.067104     1.000000     0.333333        6.0   \n",
       "1166         0.278233      0.081918     0.200000     0.250000       69.0   \n",
       "1167         0.083359      0.059012     1.000000     0.500000        3.0   \n",
       "\n",
       "         numword_2  attack  \n",
       "Num_con                     \n",
       "0            137.0       1  \n",
       "1             36.0       0  \n",
       "2              4.0       1  \n",
       "3            129.0       0  \n",
       "4            163.0       1  \n",
       "...            ...     ...  \n",
       "1163         169.0       1  \n",
       "1164         144.0       1  \n",
       "1165          37.0       0  \n",
       "1166          48.0       1  \n",
       "1167          16.0       0  \n",
       "\n",
       "[1168 rows x 7 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_uni = pd.concat([data_pol,data_sen,data_tal],axis=1)\n",
    "data_uni = data_uni.drop(['attack_p','attack_s'],axis=1)\n",
    "data_uni = data_uni.rename(columns={'attack_t':'attack'})\n",
    "data_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Politeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691273\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               attack_p   No. Observations:                 1168\n",
      "Model:                          Logit   Df Residuals:                     1165\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 12 Dec 2020   Pseudo R-squ.:                0.002704\n",
      "Time:                        16:26:14   Log-Likelihood:                -807.41\n",
      "converged:                       True   LL-Null:                       -809.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1120\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        0.1640      0.099      1.663      0.096      -0.029       0.357\n",
      "pre_polite_1    -0.3481      0.215     -1.621      0.105      -0.769       0.073\n",
      "pre_polite_2    -0.3066      0.293     -1.047      0.295      -0.881       0.268\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import logit\n",
    "data_log_p = logit(formula='attack_p ~ pre_polite_1+pre_polite_2', data=data_pol).fit()\n",
    "print(data_log_p.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 2), (1168,))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p = data_pol[['pre_polite_1','pre_polite_2']]\n",
    "y_p = np.array(data_pol['attack_p'])\n",
    "X_p.shape, y_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57692308, 0.4957265 , 0.50854701, 0.53648069, 0.54506438])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_p = cross_val_score(clf, X_p, y_p, cv=5)\n",
    "scores_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_CI(data, nbr_draws):\n",
    "    means = np.zeros(nbr_draws)\n",
    "    data = np.array(data)\n",
    "\n",
    "    for n in range(nbr_draws):\n",
    "        indices = np.random.randint(0, len(data), len(data))\n",
    "        data_tmp = data[indices] \n",
    "        means[n] = np.nanmean(data_tmp)\n",
    "        \n",
    "    dis = np.nanpercentile(means, 97.5)-np.nanpercentile(means, 2.5)\n",
    "    CI = dis.astype(float)\n",
    "\n",
    "    return CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of politeness: 53.25% (+/- 0.046)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of politeness: %0.2f%% (+/- %0.3f)\" % (np.mean(scores_p)*100, bootstrap_CI(scores_p, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691150\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               attack_s   No. Observations:                 1168\n",
      "Model:                          Logit   Df Residuals:                     1165\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 12 Dec 2020   Pseudo R-squ.:                0.002882\n",
      "Time:                        18:38:36   Log-Likelihood:                -807.26\n",
      "converged:                       True   LL-Null:                       -809.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.09700\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.1045      0.133      0.784      0.433      -0.157       0.366\n",
      "score_sen_1     0.2135      0.204      1.047      0.295      -0.186       0.613\n",
      "score_sen_2    -0.3500      0.177     -1.972      0.049      -0.698      -0.002\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "data_log_s = logit(formula='attack_s ~ score_sen_1+score_sen_2', data=data_sen).fit()\n",
    "print(data_log_s.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 2), (1168,))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_s = data_sen[['score_sen_1','score_sen_2']]\n",
    "y_s = np.array(data_sen['attack_s'])\n",
    "X_s.shape, y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52564103, 0.48290598, 0.48717949, 0.53218884, 0.55364807])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_s = cross_val_score(clf, X_s, y_s, cv=5)\n",
    "scores_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sensitiveness: 51.63% (+/- 0.047)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of sensitiveness: %0.2f%% (+/- %0.3f)\" % (np.mean(scores_s)*100, bootstrap_CI(scores_s, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Talkativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692528\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               attack_s   No. Observations:                 1168\n",
      "Model:                          Logit   Df Residuals:                     1165\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 12 Dec 2020   Pseudo R-squ.:                0.002882\n",
      "Time:                        16:44:53   Log-Likelihood:                -807.26\n",
      "converged:                       True   LL-Null:                       -809.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.09700\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.1045      0.133      0.784      0.433      -0.157       0.366\n",
      "score_sen_1     0.2135      0.204      1.047      0.295      -0.186       0.613\n",
      "score_sen_2    -0.3500      0.177     -1.972      0.049      -0.698      -0.002\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "data_log_t = logit(formula='attack_t ~ numword_1+numword_2', data=data_tal).fit()\n",
    "print(data_log_s.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 2), (1168,))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = data_tal[['numword_1','numword_2']]\n",
    "y_t = np.array(data_tal['attack_t'])\n",
    "X_t.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52991453, 0.46153846, 0.51282051, 0.5193133 , 0.50643777])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_t = cross_val_score(clf, X_t, y_t, cv=5)\n",
    "scores_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of talkativeness: 50.60% (+/- 0.039)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of talkativeness: %0.2f%% (+/- %0.3f)\" % (np.mean(scores_t)*100, bootstrap_CI(scores_t, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Unitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687183\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 attack   No. Observations:                 1168\n",
      "Model:                          Logit   Df Residuals:                     1161\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sat, 12 Dec 2020   Pseudo R-squ.:                0.008604\n",
      "Time:                        16:53:33   Log-Likelihood:                -802.63\n",
      "converged:                       True   LL-Null:                       -809.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.03041\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        0.7499      0.267      2.805      0.005       0.226       1.274\n",
      "pre_polite_1    -0.3254      0.227     -1.432      0.152      -0.771       0.120\n",
      "pre_polite_2    -0.5289      0.315     -1.680      0.093      -1.146       0.088\n",
      "score_sen_1     -0.0425      0.257     -0.165      0.869      -0.547       0.462\n",
      "score_sen_2     -0.6991      0.240     -2.918      0.004      -1.169      -0.229\n",
      "numword_1       -0.0009      0.001     -0.796      0.426      -0.003       0.001\n",
      "numword_2       -0.0026      0.002     -1.443      0.149      -0.006       0.001\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_log_u = logit(formula='attack ~ pre_polite_1+pre_polite_2+score_sen_1+score_sen_2+numword_1+numword_2', data=data_uni).fit()\n",
    "print(data_log_u.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 6), (1168,))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_u = data_uni[['pre_polite_1','pre_polite_2','score_sen_1','score_sen_2','numword_1','numword_2']]\n",
    "y_u = np.array(data_uni['attack'])\n",
    "X_u.shape, y_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53846154, 0.50854701, 0.4957265 , 0.55364807, 0.54077253])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_u = cross_val_score(clf, X_u, y_u, cv=5)\n",
    "scores_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of politeness: 53.25% (+/- 0.049)\n",
      "Accuracy of sensitiveness: 51.63% (+/- 0.046)\n",
      "Accuracy of talkativeness: 50.60% (+/- 0.040)\n",
      "Accuracy across all selected features: 52.74% (+/- 0.039)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of politeness: %0.2f%% (+/- %0.3f)\" % (np.mean(scores_p)*100, bootstrap_CI(scores_p, 1000)))\n",
    "print(\"Accuracy of sensitiveness: %0.2f%% (+/- %0.3f)\" % (np.mean(scores_s)*100, bootstrap_CI(scores_s, 1000)))\n",
    "print(\"Accuracy of talkativeness: %0.2f%% (+/- %0.3f)\" % (np.mean(scores_t)*100, bootstrap_CI(scores_t, 1000)))\n",
    "print(\"Accuracy across all selected features: %0.2f%% (+/- %0.3f)\" % (np.mean(scores_u)*100, bootstrap_CI(scores_u, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
